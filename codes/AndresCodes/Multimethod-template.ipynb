{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8403d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy.stats import poisson\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b644f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity # paquete necesario\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d2a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6020b5fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need\n",
    "pred_XG_SM # background test-dataset (output of the ML)\n",
    "pred_XG_NP # signal test-dataset (output of the ML)\n",
    "\n",
    "B_expected # number of background events expected in your experiment\n",
    "S_expected # number of signal events expected in your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c77d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb7ed2de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SOME PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b6f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5000 # number of iterations, to search the optimal binning\n",
    "\n",
    "MIN_EVS = 5 # minimum number of events per bin\n",
    "\n",
    "n_ensembles = 5000 # number of pseudo experiments to compute Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb2255",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Determine number of bins with 'bin_edges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fefa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' NUMBER OF BINS')\n",
    "\n",
    "divs_B = int(len(pred_XG_SM)/B_expected)\n",
    "\n",
    "B_1 = []\n",
    "B_2 = []\n",
    "B_3 = []\n",
    "\n",
    "for it in range(divs_B):\n",
    "    datB_grid_SM = pred_XG_SM[(B_expected*it):(B_expected*(it+1))]\n",
    "    datB_grid_NP = pred_XG_NP[:B_expected]\n",
    "\n",
    "    B_hist1 = np.histogram_bin_edges(datB_grid_SM, bins = 'fd')\n",
    "    B_hist2 = np.histogram_bin_edges(datB_grid_SM, bins = 'doane')\n",
    "    B_hist3 = np.histogram_bin_edges(datB_grid_SM, bins = 'sturges')\n",
    "    \n",
    "    B_1.append(len(B_hist1))\n",
    "    B_2.append(len(B_hist2))\n",
    "    B_3.append(len(B_hist3))\n",
    "\n",
    "\n",
    "\n",
    "B_1_mean = int(np.mean(B_1))\n",
    "B_2_mean = int(np.mean(B_2))\n",
    "B_3_mean = int(np.mean(B_3))\n",
    "\n",
    "\n",
    "B_hist1 = plt.hist(datB_grid_SM, bins = B_1_mean, histtype = 'step', label = 'fd')\n",
    "B_hist2 = plt.hist(datB_grid_SM, bins = B_2_mean, histtype = 'step', label = 'doane')\n",
    "B_hist3 = plt.hist(datB_grid_SM, bins = B_3_mean, histtype = 'step', label = 'sturges')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('fd', B_1_mean)\n",
    "print('doane', B_2_mean)\n",
    "print('sturges', B_3_mean)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "# SAVE THE OPTIMAL BIN NUMBER\n",
    "B_bins_mean = [B_1_mean, B_2_mean, B_3_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6e5c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BIN LIKELIHOOD with the 'optimal' number of bins (equal size bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067cbe3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### without statistical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "# Z_bins_XG_CV # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_zeros # replacing the zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# EQ SIZE CROSS-VAL FOR Nbins #\n",
    "###############################\n",
    "\n",
    "print('\\n BINNING: eq size bins, with the optimal number of bins: ')\n",
    "\n",
    "\n",
    "print('minimum number of events per bin: ', MIN_EVS)\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "Z_bins_XG_CV = []\n",
    "Z_bins_XG_CV_zeros = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Les't find the number of possible ensembles\n",
    "N_ensembles_back = len(pred_XG_SM) / B_expected\n",
    "N_ensembles_sig = len(pred_XG_NP) / S_expected\n",
    "\n",
    "\n",
    "\n",
    "for j_it in range(len(B_bins_mean)):\n",
    "    \n",
    "    # bin the parameter space of all background events\n",
    "    hist_back, binedges_back = np.histogramdd([pred_XG_SM], bins=(B_bins_mean[j_it]), range = [[min(pred_XG_SM),max(pred_XG_SM)]])\n",
    "    bin_edges = binedges_back[0]\n",
    "    \n",
    "    if min(hist_back) >= MIN_EVS*N_ensembles_back:\n",
    "        print('ok j_it=', j_it)\n",
    "        \n",
    "        # now divide by the number of possible ensembles\n",
    "        back_prom = hist_back/N_ensembles_back\n",
    "\n",
    "        # same for signal\n",
    "        hist_sig, binedges_sig = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "        sig_prom = hist_sig/N_ensembles_sig\n",
    "\n",
    "        # then the signif Z^binned-Asimov:\n",
    "        Z_bins_XG_CV_aux = ( 2* sum( ( back_prom * np.log( back_prom / (sig_prom+back_prom) ) ) + sig_prom ) )**0.5\n",
    "\n",
    "    else:\n",
    "        print('NO ok j_it=', j_it)\n",
    "        Z_bins_XG_CV_aux = 0\n",
    "        \n",
    "    Z_bins_XG_CV.append(Z_bins_XG_CV_aux)\n",
    "    \n",
    "    \n",
    "    # REPLACING the zeros\n",
    "    hist_back_noceros = []\n",
    "    for i in range(len(hist_back)):\n",
    "        if hist_back[i]!=0:\n",
    "            hist_back_noceros.append(hist_back[i])\n",
    "\n",
    "    min_back = min(hist_back_noceros)\n",
    "\n",
    "    # replace the zeros\n",
    "    for i in range(len(hist_back)):\n",
    "        if hist_back[i]==0:\n",
    "            hist_back[i] = min_back\n",
    "\n",
    "    # now divide by the number of possible ensembles\n",
    "    back_prom = hist_back/N_ensembles_back\n",
    "\n",
    "    # same for signal\n",
    "    hist_sig, binedges_sig = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "    sig_prom = hist_sig/N_ensembles_sig\n",
    "    \n",
    "    Z_bins_XG_CV_zeros.append( ( 2* sum( ( back_prom * np.log( back_prom / (sig_prom+back_prom) ) ) + sig_prom ) )**0.5 )\n",
    "\n",
    "\n",
    "\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460b034",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### with statistical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "# Z_bins_XG_CV_stat # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_stat_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_stat_min # central value -1sigma\n",
    "\n",
    "# Z_bins_XG_CV_stat_zeros # replacing the zeros\n",
    "# Z_bins_XG_CV_stat_zeros_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_stat_zeros_min # central value -1sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# EQ SIZE CROSS-VAL FOR Nbins #\n",
    "###############################\n",
    "\n",
    "print('\\n BINNING: eq size bins, with the optimal number of bins: ')\n",
    "\n",
    "\n",
    "print('minimum number of events per bin: ', MIN_EVS)\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "Z_bins_XG_CV_stat = []\n",
    "Z_bins_XG_CV_stat_zeros = []\n",
    "\n",
    "Z_bins_XG_CV_stat_std = []\n",
    "Z_bins_XG_CV_stat_zeros_std = []\n",
    "\n",
    "\n",
    "\n",
    "print('B_expected: ', B_expected)\n",
    "print('S_expected: ', S_expected)\n",
    "\n",
    "\n",
    "# to construct ensembles B and S events are taken from Poisson distributions\n",
    "mu = S_expected + B_expected\n",
    "\n",
    "\n",
    "# Letś find the number of events per ensemble such that we get at least one ensemble populated if events are taken from a Poisson distribution\n",
    "\n",
    "# around the mean its populated so let's try (proposed range to be checked)\n",
    "list_events_per_ensembles = [i for i in range(int(mu*0.9),int(mu*1.1))]\n",
    "to_check = len(list_events_per_ensembles)\n",
    "\n",
    "# I want at least one ensemble populated\n",
    "list_nums_ensembles = [ int( poisson.pmf(list_events_per_ensembles[i],mu)*n_ensembles ) for i in range(len(list_events_per_ensembles)) ]\n",
    "\n",
    "\n",
    "\n",
    "# Remove from the list the elements without at least 1 ensemble possible\n",
    "for i in range(len(list_events_per_ensembles)):\n",
    "    if list_nums_ensembles[i] > 1:\n",
    "        list_events_per_ensembles = list_events_per_ensembles[i:]\n",
    "        list_nums_ensembles = list_nums_ensembles[i:]\n",
    "        break\n",
    "\n",
    "\n",
    "for i in range(len(list_events_per_ensembles)):\n",
    "    if list_nums_ensembles[i] < 1:\n",
    "        list_events_per_ensembles = list_events_per_ensembles[:i]\n",
    "        list_nums_ensembles = list_nums_ensembles[:i]\n",
    "        break\n",
    "\n",
    "print('\\n If ', to_check, ' = ', len(list_events_per_ensembles), '   then the proposed range has to be extended')\n",
    "\n",
    "print('n_ensembles (actual): ', sum(list_nums_ensembles))\n",
    "\n",
    "\n",
    "\n",
    "# lists of S and B events per ensemble, w.r.t the total of number of events per ensemble found above:\n",
    "\n",
    "p_berno = S_expected/(S_expected+B_expected)\n",
    "\n",
    "list_S_per_ensembles = []\n",
    "list_B_per_ensembles = []\n",
    "\n",
    "for jj in range(len(list_events_per_ensembles)):\n",
    "    list_S_per_ensembles.append( int(p_berno * list_events_per_ensembles[jj]) )\n",
    "    list_B_per_ensembles.append( list_events_per_ensembles[jj] - int(p_berno * list_events_per_ensembles[jj]) )\n",
    "\n",
    "######\n",
    "# NOW I HAVE 4 LISTS:\n",
    "# list_events_per_ensembles     list with the number of events per ensemble (its a range)\n",
    "# list_nums_ensembles           list with the number of ensembles, w.r.t the 1st list\n",
    "# list_S_per_ensembles          list with the number of signal events in each ensembles, w.r.t the 1st list\n",
    "# list_B_per_ensembles          list with the number of background events in each ensembles, w.r.t the 1st list\n",
    "######\n",
    "    \n",
    "\n",
    "Z_bins_XG_CV_stat_aux = []\n",
    "Z_bins_XG_CV_stat_aux_zeros = []\n",
    "\n",
    "for j_it in range(len(B_bins_mean)):\n",
    "    \n",
    "    for bb in range(len(list_nums_ensembles)):\n",
    "\n",
    "        for kk in range(list_nums_ensembles[bb]):\n",
    "            \n",
    "            ran_ind_B = np.random.choice(indices_B, list_B_per_ensembles[bb])\n",
    "            ran_ind_S = np.random.choice(indices_S, list_S_per_ensembles[bb])\n",
    "            \n",
    "            # estimate the variance in each bin as ~ (upB - downB)/2 \n",
    "            \n",
    "            pred_XG_SM_shuf = []\n",
    "            \n",
    "            pred_XG_NP_shuf = []\n",
    "            \n",
    "            for ill in ran_ind_B:\n",
    "                pred_XG_SM_shuf.append(pred_XG_SM[ill])\n",
    "                \n",
    "            for ill in ran_ind_S:\n",
    "                pred_XG_NP_shuf.append(pred_XG_NP[ill])\n",
    "                \n",
    "            \n",
    "\n",
    "            # Let's find out the expected number of B and S events in each bin:       \n",
    "\n",
    "            # bin the parameter space of all background events\n",
    "            hist_back, binedges_back = np.histogramdd([pred_XG_SM_shuf], bins=(B_bins_mean[j_it]), range = [[min(pred_XG_SM_shuf),max(pred_XG_SM_shuf)]])\n",
    "            bin_edges = binedges_back[0]\n",
    "            \n",
    "            back_prom = hist_back.T.ravel()\n",
    "            \n",
    "            \n",
    "            if min(hist_back) >= MIN_EVS:\n",
    "                print('ok j_it=', j_it)\n",
    "\n",
    "                # same for signal\n",
    "                hist_sig, binedges_sig = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "                sig_prom = hist_sig.T.ravel()\n",
    "\n",
    "                # then the signif Z^binned-Asimov:\n",
    "                Z_bins_XG_CV_stat_aux = ( 2* sum( ( back_prom * np.log( back_prom / (sig_prom+back_prom) ) ) + sig_prom ) )**0.5\n",
    "\n",
    "            else:\n",
    "                print('NO ok j_it=', j_it)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            # If a bins has no expected background events replace that zero for the minimum B_bin=/=0\n",
    "\n",
    "            # find the minimum\n",
    "            back_prom_noceros = []\n",
    "            for i in range(len(back_prom)):\n",
    "                if back_prom[i]!=0:\n",
    "                    back_prom_noceros.append(back_prom[i])\n",
    "\n",
    "            min_back = min(back_prom_noceros)\n",
    "\n",
    "            # replace the zeros\n",
    "            for i in range(len(back_prom)):\n",
    "                if back_prom[i]==0:\n",
    "                    back_prom[i] = min_back\n",
    "                    \n",
    "                    \n",
    "            # same for signal\n",
    "            hist_sig, binedges_sig = np.histogramdd([pred_XG_NP_shuf], bins=[bin_edges])\n",
    "            sig_prom = hist_sig.T.ravel()\n",
    "            \n",
    "            Z_bins_XG_CV_stat_aux_zeros.append( ( 2* sum( ( back_prom * np.log( back_prom / (sig_prom+back_prom) ) ) + sig_prom ) )**0.5 )\n",
    "\n",
    "                    \n",
    "                    \n",
    "    # Histogram of q_muhats\n",
    "    \n",
    "    print(' CHECK IF YOU HAVE ENOUGH PSEUDO EXPERIMENTS (cause you ask for a minimun number of events per bin): ')\n",
    "    print('pseudo experiments tested: ', n_ensembles)\n",
    "    print('pseudo experiments that have at least ', MIN_EVS, ' events per bin: ', len(Z_bins_XG_CV_stat_aux))\n",
    "    print('\\n you need at least... 1000? to describe the distibution')\n",
    "    print(' if not, increase the number of pseudo experiments' )\n",
    "\n",
    "    weights = np.ones_like(Z_bins_XG_CV_stat_aux)/float(len(Z_bins_XG_CV_stat_aux))\n",
    "    nMIX, binsMIX, patchesMIX = plt.hist(Z_bins_XG_CV_stat_aux, 25, weights=weights, histtype='step', color='blue', linewidth=2)\n",
    "    weights = np.ones_like(Z_bins_XG_CV_stat_aux_zeros)/float(len(Z_bins_XG_CV_stat_aux_zeros))\n",
    "    nMIX, binsMIX, patchesMIX = plt.hist(Z_bins_XG_CV_stat_aux_zeros, 25, weights=weights, histtype='step', color='green', linewidth=2)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"Z\",fontsize=16)\n",
    "    plt.ylabel(\"Fraction of ensembles\",fontsize=16)\n",
    "    plt.grid()\n",
    "    #plt.legend(fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Remove nan if any\n",
    "    Z_bins_XG_CV_stat_aux = [x for x in Z_bins_XG_CV_stat_aux if x == x]\n",
    "    for jk in range(len(Z_bins_XG_CV_stat_aux)):\n",
    "        if Z_bins_XG_CV_stat_aux[jk] < 0:\n",
    "            Z_bins_XG_CV_stat_aux[jk] = 0\n",
    "\n",
    "    Z_bins_XG_CV_stat_median = np.median(Z_bins_XG_CV_stat_aux)   \n",
    "    Z_bins_XG_CV_stat.append(Z_bins_XG_CV_stat_median)\n",
    "    \n",
    "    Z_bins_XG_CV_stat_stdX = np.std(Z_bins_XG_CV_stat_aux)   \n",
    "    Z_bins_XG_CV_stat_std.append(Z_bins_XG_CV_stat_stdX)\n",
    "\n",
    "    print('# bins: ', B_bins_mean[j_it])\n",
    "    print('Z median: ', Z_bins_XG_CV_stat_median)\n",
    "    print('Z std: ', Z_bins_XG_CV_stat_stdX)\n",
    "    \n",
    "    \n",
    "    # Remove nan if any\n",
    "    Z_bins_XG_CV_stat_aux_zeros = [x for x in Z_bins_XG_CV_stat_aux_zeros if x == x]\n",
    "    for jk in range(len(Z_bins_XG_CV_stat_aux_zeros)):\n",
    "        if Z_bins_XG_CV_stat_aux_zeros[jk] < 0:\n",
    "            Z_bins_XG_CV_stat_aux_zeros[jk] = 0\n",
    "\n",
    "    Z_bins_XG_CV_stat_zeros_median = np.median(Z_bins_XG_CV_stat_aux_zeros)   \n",
    "    Z_bins_XG_CV_stat_zeros.append(Z_bins_XG_CV_stat_zeros_median)\n",
    "    \n",
    "    Z_bins_XG_CV_stat_zeros_stdX = np.std(Z_bins_XG_CV_stat_aux_zeros)   \n",
    "    Z_bins_XG_CV_stat_zeros_std.append(Z_bins_XG_CV_stat_zeros_stdX)\n",
    "\n",
    "    print('# bins: ', B_bins_mean[j_it])\n",
    "    print('Z median: ', Z_bins_XG_CV_stat_zeros_median)\n",
    "    print('Z std: ', Z_bins_XG_CV_stat_zeros_stdX)\n",
    "    print('')\n",
    "\n",
    "print(' ')\n",
    "\n",
    "\n",
    "Z_bins_XG_CV_stat_plus = [i+j for i, j in zip(Z_bins_XG_CV_stat, Z_bins_XG_CV_stat_std)]\n",
    "Z_bins_XG_CV_stat_min = [i-j for i, j in zip(Z_bins_XG_CV_stat, Z_bins_XG_CV_stat_std)]\n",
    "\n",
    "Z_bins_XG_CV_stat_zeros_plus = [i+j for i, j in zip(Z_bins_XG_CV_stat_zeros, Z_bins_XG_CV_stat_zeros_std)]\n",
    "Z_bins_XG_CV_stat_zeros_min = [i-j for i, j in zip(Z_bins_XG_CV_stat_zeros, Z_bins_XG_CV_stat_zeros_std)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9984bea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BIN LIKELIHOOD with the 'optimal' number of bins (same number of background events per bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89d051",
   "metadata": {},
   "source": [
    "#### without statistical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "# Z_bins_XG_CV_eqBperbin # asking for a min number of events per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eee781",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# EQ back events per bin CROSS-VAL FOR Nbins #\n",
    "##############################################\n",
    "\n",
    "print('\\n BINNING: eq background events per bin, with the optimal number of bins: ')\n",
    "\n",
    "\n",
    "print('minimum number of events per bin: ', MIN_EVS)\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "Z_bins_XG_CV_eqBperbin = []\n",
    "\n",
    "\n",
    "\n",
    "# Les't find the number of possible ensembles\n",
    "N_ensembles_back = len(pred_XG_SM) / B_expected\n",
    "N_ensembles_sig = len(pred_XG_NP) / S_expected\n",
    "\n",
    "\n",
    "\n",
    "for j_it in range(len(B_bins_mean)):\n",
    "    \n",
    "    # same number of B events per bin\n",
    "    bin_edges_same = pd.qcut(pd.DataFrame(pred_XG_SM)[0] + jitter(pd.DataFrame(pred_XG_SM)[0]), q = B_bins_mean[j_it], precision=0, retbins = True)[1]\n",
    "    bin_edges = bin_edges_same\n",
    "    \n",
    "    # bin the parameter space of all background events\n",
    "    hist_back, binedges_back = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "    \n",
    "    if min(hist_back) >= MIN_EVS*N_ensembles_back:\n",
    "        print('ok j_it=', j_it)\n",
    "        \n",
    "        # now divide by the number of possible ensembles\n",
    "        back_prom = hist_back/N_ensembles_back\n",
    "\n",
    "        # same for signal\n",
    "        hist_sig, binedges_sig = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "        sig_prom = hist_sig/N_ensembles_sig\n",
    "\n",
    "        # then the signif Z^binned-Asimov:\n",
    "        Z_bins_XG_CV_eqBperbin_aux = ( 2* sum( ( back_prom * np.log( back_prom / (sig_prom+back_prom) ) ) + sig_prom ) )**0.5\n",
    "\n",
    "    else:\n",
    "        print('NO ok j_it=', j_it)\n",
    "        Z_bins_XG_CV_eqBperbin_aux = 0\n",
    "        \n",
    "    Z_bins_XG_CV_eqBperbin.append(Z_bins_XG_CV_eqBperbin_aux)\n",
    "    \n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249eb917",
   "metadata": {},
   "source": [
    "#### with statistical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "# Z_bins_XG_CV_eqBperbin_stat # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_eqBperbin_stat_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_eqBperbin_stat_min # central value -1sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e63afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# EQ back events per bin CROSS-VAL FOR Nbins #\n",
    "##############################################\n",
    "\n",
    "print('\\n BINNING: eq background events per bin, with the optimal number of bins: ')\n",
    "\n",
    "\n",
    "print('minimum number of events per bin: ', MIN_EVS)\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "Z_bins_XG_CV_eqBperbin_stat = []\n",
    "Z_bins_XG_CV_eqBperbin_stat_std = []\n",
    "\n",
    "\n",
    "\n",
    "print('B_expected: ', B_expected)\n",
    "print('S_expected: ', S_expected)\n",
    "\n",
    "\n",
    "# to construct ensembles B and S events are taken from Poisson distributions\n",
    "mu = S_expected + B_expected\n",
    "\n",
    "\n",
    "# Letś find the number of events per ensemble such that we get at least one ensemble populated if events are taken from a Poisson distribution\n",
    "\n",
    "# around the mean its populated so let's try (proposed range to be checked)\n",
    "list_events_per_ensembles = [i for i in range(int(mu*0.9),int(mu*1.1))]\n",
    "to_check = len(list_events_per_ensembles)\n",
    "\n",
    "# I want at least one ensemble populated\n",
    "list_nums_ensembles = [ int( poisson.pmf(list_events_per_ensembles[i],mu)*n_ensembles ) for i in range(len(list_events_per_ensembles)) ]\n",
    "\n",
    "\n",
    "\n",
    "# Remove from the list the elements without at least 1 ensemble possible\n",
    "for i in range(len(list_events_per_ensembles)):\n",
    "    if list_nums_ensembles[i] > 1:\n",
    "        list_events_per_ensembles = list_events_per_ensembles[i:]\n",
    "        list_nums_ensembles = list_nums_ensembles[i:]\n",
    "        break\n",
    "\n",
    "\n",
    "for i in range(len(list_events_per_ensembles)):\n",
    "    if list_nums_ensembles[i] < 1:\n",
    "        list_events_per_ensembles = list_events_per_ensembles[:i]\n",
    "        list_nums_ensembles = list_nums_ensembles[:i]\n",
    "        break\n",
    "\n",
    "print('\\n If ', to_check, ' = ', len(list_events_per_ensembles), '   then the proposed range has to be extended')\n",
    "\n",
    "print('n_ensembles (actual): ', sum(list_nums_ensembles))\n",
    "\n",
    "\n",
    "\n",
    "# lists of S and B events per ensemble, w.r.t the total of number of events per ensemble found above:\n",
    "\n",
    "p_berno = S_expected/(S_expected+B_expected)\n",
    "\n",
    "list_S_per_ensembles = []\n",
    "list_B_per_ensembles = []\n",
    "\n",
    "for jj in range(len(list_events_per_ensembles)):\n",
    "    list_S_per_ensembles.append( int(p_berno * list_events_per_ensembles[jj]) )\n",
    "    list_B_per_ensembles.append( list_events_per_ensembles[jj] - int(p_berno * list_events_per_ensembles[jj]) )\n",
    "\n",
    "######\n",
    "# NOW I HAVE 4 LISTS:\n",
    "# list_events_per_ensembles     list with the number of events per ensemble (its a range)\n",
    "# list_nums_ensembles           list with the number of ensembles, w.r.t the 1st list\n",
    "# list_S_per_ensembles          list with the number of signal events in each ensembles, w.r.t the 1st list\n",
    "# list_B_per_ensembles          list with the number of background events in each ensembles, w.r.t the 1st list\n",
    "######\n",
    "    \n",
    "\n",
    "Z_bins_XG_CV_stat_aux = []\n",
    "\n",
    "for j_it in range(len(B_bins_mean)):\n",
    "    \n",
    "    for bb in range(len(list_nums_ensembles)):\n",
    "\n",
    "        for kk in range(list_nums_ensembles[bb]):\n",
    "            \n",
    "            ran_ind_B = np.random.choice(indices_B, list_B_per_ensembles[bb])\n",
    "            ran_ind_S = np.random.choice(indices_S, list_S_per_ensembles[bb])\n",
    "            \n",
    "            # estimate the variance in each bin as ~ (upB - downB)/2 \n",
    "            \n",
    "            pred_XG_SM_shuf = []\n",
    "            \n",
    "            pred_XG_NP_shuf = []\n",
    "            \n",
    "            for ill in ran_ind_B:\n",
    "                pred_XG_SM_shuf.append(pred_XG_SM[ill])\n",
    "                \n",
    "            for ill in ran_ind_S:\n",
    "                pred_XG_NP_shuf.append(pred_XG_NP[ill])\n",
    "                \n",
    "                \n",
    "                \n",
    "            # same number of B events per bin\n",
    "            bin_edges_same = pd.qcut(pd.DataFrame(pred_XG_SM_shuf)[0] + jitter(pd.DataFrame(pred_XG_SM_shuf)[0]), q = B_bins_mean[j_it], precision=0, retbins = True)[1]\n",
    "            bin_edges = bin_edges_same\n",
    "    \n",
    "            # bin the parameter space of all background events\n",
    "            hist_back, binedges_back = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "            \n",
    "            back_prom = hist_back.T.ravel()\n",
    "            \n",
    "            \n",
    "            if min(hist_back) >= MIN_EVS:\n",
    "                print('ok j_it=', j_it)\n",
    "\n",
    "                # same for signal\n",
    "                hist_sig, binedges_sig = np.histogramdd([pred_XG_NP], bins=[bin_edges])\n",
    "                sig_prom = hist_sig.T.ravel()\n",
    "\n",
    "                # then the signif Z^binned-Asimov:\n",
    "                Z_bins_XG_CV_stat_aux = ( 2* sum( ( back_prom * np.log( back_prom / (sig_prom+back_prom) ) ) + sig_prom ) )**0.5\n",
    "\n",
    "            else:\n",
    "                print('NO ok j_it=', j_it)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "                    \n",
    "    # Histogram of q_muhats\n",
    "    \n",
    "    print(' CHECK IF YOU HAVE ENOUGH PSEUDO EXPERIMENTS (cause you ask for a minimun number of events per bin): ')\n",
    "    print('pseudo experiments tested: ', n_ensembles)\n",
    "    print('pseudo experiments that have at least ', MIN_EVS, ' events per bin: ', len(Z_bins_XG_CV_stat_aux))\n",
    "    print('\\n you need at least... 1000? to describe the distibution')\n",
    "    print(' if not, increase the number of pseudo experiments' )\n",
    "\n",
    "    weights = np.ones_like(Z_bins_XG_CV_stat_aux)/float(len(Z_bins_XG_CV_stat_aux))\n",
    "    nMIX, binsMIX, patchesMIX = plt.hist(Z_bins_XG_CV_stat_aux, 25, weights=weights, histtype='step', color='blue', linewidth=2)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"Z\",fontsize=16)\n",
    "    plt.ylabel(\"Fraction of ensembles\",fontsize=16)\n",
    "    plt.grid()\n",
    "    #plt.legend(fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Remove nan if any\n",
    "    Z_bins_XG_CV_stat_aux = [x for x in Z_bins_XG_CV_stat_aux if x == x]\n",
    "    for jk in range(len(Z_bins_XG_CV_stat_aux)):\n",
    "        if Z_bins_XG_CV_stat_aux[jk] < 0:\n",
    "            Z_bins_XG_CV_stat_aux[jk] = 0\n",
    "\n",
    "    Z_bins_XG_CV_stat_median = np.median(Z_bins_XG_CV_stat_aux)   \n",
    "    Z_bins_XG_CV_eqBperbin_stat.append(Z_bins_XG_CV_stat_median)\n",
    "    \n",
    "    Z_bins_XG_CV_stat_stdX = np.std(Z_bins_XG_CV_stat_aux)   \n",
    "    Z_bins_XG_CV_eqBperbin_stat_std.append(Z_bins_XG_CV_stat_stdX)\n",
    "\n",
    "    print('# bins: ', B_bins_mean[j_it])\n",
    "    print('Z median: ', Z_bins_XG_CV_stat_median)\n",
    "    print('Z std: ', Z_bins_XG_CV_stat_stdX)\n",
    "    print('')\n",
    "\n",
    "print(' ')\n",
    "\n",
    "\n",
    "Z_bins_XG_CV_eqBperbin_stat_plus = [i+j for i, j in zip(Z_bins_XG_CV_eqBperbin_stat, Z_bins_XG_CV_eqBperbin_stat_std)]\n",
    "Z_bins_XG_CV_eqBperbin_stat_min = [i-j for i, j in zip(Z_bins_XG_CV_eqBperbin_stat, Z_bins_XG_CV_eqBperbin_stat_std)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7606abd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BIN LIKELIHOOD GRID with the 'optimal' number of bins but varying size of bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED ALL THE ITERATIONS IN:\n",
    "\n",
    "# metric value\n",
    "# poiss # asking for a min number of events per bin\n",
    "# poiss_zeros # replacing the zeros\n",
    "\n",
    "# Z value\n",
    "# Z_bins_XG_CV_rd # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_rd_zeros # replacing the zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a82edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# RANDOM BINNING with CROSS-VAL FOR Nbins and CROSS-VAL for the random #\n",
    "########################################################################\n",
    "\n",
    "# divide the test set in 6 sub sets:\n",
    "# 4 used to compute the grid\n",
    "# 1 used to compute the metric (chi2 for example)\n",
    "# 1 used to compute Z\n",
    "\n",
    "num_SM = int(len(pred_XG_SM)/6)\n",
    "num_NP = int(len(pred_XG_NP)/6)\n",
    "\n",
    "numdat = min(num_SM, num_NP)\n",
    "\n",
    "data_grid_SM_0 = pred_XG_SM[(0*numdat):(1*numdat)]\n",
    "data_grid_NP_0 = pred_XG_NP[(0*numdat):(1*numdat)]\n",
    "\n",
    "data_grid_SM_1 = pred_XG_SM[(1*numdat):(2*numdat)]\n",
    "data_grid_NP_1 = pred_XG_NP[(1*numdat):(2*numdat)]\n",
    "                            \n",
    "data_grid_SM_2 = pred_XG_SM[(2*numdat):(3*numdat)]\n",
    "data_grid_NP_2 = pred_XG_NP[(2*numdat):(3*numdat)]\n",
    "                          \n",
    "data_grid_SM_3 = pred_XG_SM[(3*numdat):(4*numdat)]\n",
    "data_grid_NP_3 = pred_XG_NP[(3*numdat):(4*numdat)]\n",
    "                                                        \n",
    "data_grid_SM_4 = pred_XG_SM[(4*numdat):(5*numdat)]\n",
    "data_grid_NP_4 = pred_XG_NP[(4*numdat):(5*numdat)]\n",
    "\n",
    "data_grid_SM_5 = pred_XG_SM[(5*numdat):(6*numdat)]\n",
    "data_grid_NP_5 = pred_XG_NP[(5*numdat):(6*numdat)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# chi2 = []\n",
    "# chi2_N = []\n",
    "# MSE = []\n",
    "poiss = []\n",
    "Z_bins_XG_CV_rd = []\n",
    "\n",
    "# chi2_zeros = []\n",
    "# chi2_N_zeros = []\n",
    "# MSE_zeros = []\n",
    "poiss_zeros = []\n",
    "Z_bins_XG_CV_rd_zeros = []\n",
    "\n",
    "\n",
    "# Les't find the number of possible ensembles\n",
    "N_ensembles_back = len(data_grid_SM_0) / B_expected\n",
    "N_ensembles_sig = len(data_grid_NP_0) / S_expected\n",
    "\n",
    "\n",
    "############\n",
    "# THE GRID #\n",
    "############\n",
    "\n",
    "# here j_it iterates over the number of bins\n",
    "# in this case we are using the 3 'optimal' bin numbers defined above\n",
    "# you can put a range, i.e.    for j_it in range(10,100):\n",
    "for j_it in range(len(B_bins_mean)):\n",
    "    \n",
    "    print('doing Nbin: ', B_bins_mean[j_it])\n",
    "\n",
    "    for i_it in range(ntrials):\n",
    "        \n",
    "        # bin the parameter space of all background events\n",
    "        if i_it == 0:\n",
    "            # for i_it=0 we are going to do equal size bins\n",
    "            bin_edges = np.linspace( min(pred_XG_SM), max(pred_XG_SM), (B_bins_mean[j_it]+1) )\n",
    "            \n",
    "        else:\n",
    "            # for i_it=/=0 random bin width\n",
    "            bin_edges = np.hstack( (min(pred_XG_SM), np.sort( np.random.uniform(min(pred_XG_SM), max(pred_XG_SM), (B_bins_mean[j_it]-1)) ), max(pred_XG_SM) ) )\n",
    "            \n",
    "        hist_SM_0, _ = np.histogramdd([data_grid_SM_0], bins = [bin_edges])\n",
    "        hist_SM_1, _ = np.histogramdd([data_grid_SM_1], bins = [bin_edges])\n",
    "        hist_SM_2, _ = np.histogramdd([data_grid_SM_2], bins = [bin_edges])\n",
    "        hist_SM_3, _ = np.histogramdd([data_grid_SM_3], bins = [bin_edges])\n",
    "        \n",
    "        # bin 4 sub sets, compute the mean to 'average' subsets\n",
    "        mean = (hist_SM_0 + hist_SM_1 + hist_SM_2 + hist_SM_3 )/4\n",
    "\n",
    "        if min(mean)>= MIN_EVS*N_ensembles_back:\n",
    "            \n",
    "            ##################\n",
    "            # COMPUTE METRIC #\n",
    "            ##################\n",
    "            hist_SM_4, _ = np.histogramdd([data_grid_SM_4], bins = [bin_edges])\n",
    "            \n",
    "#             aux_chi2 = sum( ((hist_SM_4 - mean))**2 / mean )\n",
    "#             aux_chi2_N = aux_chi2 / j_it\n",
    "#             aux_MSE = sum( ((hist_SM_4 - mean))**2 ) / j_it\n",
    "            aux_poiss = sum( mean - (hist_SM_4*np.log(mean)) + (hist_SM_4*np.log(hist_SM_4)) - hist_SM_4 )\n",
    "\n",
    "            \n",
    "            #############\n",
    "            # COMPUTE Z #\n",
    "            #############\n",
    "            # bin the parameter space of all background events\n",
    "            hist_SM_5, _ = np.histogramdd([data_grid_SM_5], bins = [bin_edges])\n",
    "            \n",
    "            # now divide by the number of possible ensembles\n",
    "            back_prom_5 = hist_SM_5/N_ensembles_back\n",
    "\n",
    "            # same for signal\n",
    "            hist_NP_5, _ = np.histogramdd([data_grid_NP_5], bins = [bin_edges])\n",
    "            \n",
    "            sig_prom_5 = hist_NP_5/N_ensembles_sig\n",
    "\n",
    "            # then the signif Z^binned-Asimov:\n",
    "            Z_bins_XG_aux = ( 2* sum( ( back_prom_5 * np.log( back_prom_5 / (sig_prom_5+back_prom_5) ) ) + sig_prom_5 ) )**0.5\n",
    "            \n",
    "      \n",
    "        else:\n",
    "#             aux_chi2 = 9999\n",
    "#             aux_chi2_N = 9999\n",
    "#             aux_chi2_sin = 9999\n",
    "            aux_poiss = 9999\n",
    "            Z_bins_XG_aux = 0\n",
    "            \n",
    "\n",
    "#         chi2.append(aux_chi2)\n",
    "#         chi2_N.append(aux_chi2_N)\n",
    "#         MSE.append(aux_chi2_sin)\n",
    "        poiss.append(aux_poiss)\n",
    "        Z_bins_XG_CV_rd.append(Z_bins_XG_aux)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # REPLACING the zeros\n",
    "        mean_noceros = []\n",
    "        for i in range(len(mean)):\n",
    "            if mean[i]!=0:\n",
    "                mean_noceros.append(mean[i])\n",
    "        \n",
    "        min_mean = min(mean_noceros)\n",
    "        \n",
    "        # replace the zeros\n",
    "        for i in range(len(mean)):\n",
    "            if mean[i]==0:\n",
    "                mean[i] = min_mean\n",
    "                \n",
    "        \n",
    "        ##################\n",
    "        # COMPUTE METRIC #\n",
    "        ##################\n",
    "        hist_SM_4, _ = np.histogramdd([data_grid_SM_4], bins = [bin_edges])\n",
    "        \n",
    "        hist_back_noceros = []\n",
    "        for i in range(len(hist_SM_4)):\n",
    "            if hist_SM_4[i]!=0:\n",
    "                hist_back_noceros.append(hist_SM_4[i])\n",
    "\n",
    "        min_back = min(hist_back_noceros)\n",
    "\n",
    "        # replace the zeros\n",
    "        for i in range(len(hist_SM_4)):\n",
    "            if hist_SM_4[i]==0:\n",
    "                hist_SM_4[i] = min_back\n",
    "\n",
    "#         aux_chi2 = sum( ((hist_SM_4 - mean))**2 / mean )\n",
    "#         aux_chi2_N = aux_chi2 / j_it\n",
    "#         aux_MSE = sum( ((hist_SM_4 - mean))**2 ) / j_it\n",
    "        aux_poiss = sum( mean - (hist_SM_4*np.log(mean)) + (hist_SM_4*np.log(hist_SM_4)) - hist_SM_4 )\n",
    "\n",
    "\n",
    "        #############\n",
    "        # COMPUTE Z #\n",
    "        #############\n",
    "        # bin the parameter space of all background events\n",
    "        hist_SM_5, _ = np.histogramdd([data_grid_SM_5], bins = [bin_edges])\n",
    "        \n",
    "        hist_back_noceros = []\n",
    "        for i in range(len(hist_SM_5)):\n",
    "            if hist_SM_5[i]!=0:\n",
    "                hist_back_noceros.append(hist_SM_5[i])\n",
    "\n",
    "        min_back = min(hist_back_noceros)\n",
    "\n",
    "        # replace the zeros\n",
    "        for i in range(len(hist_SM_5)):\n",
    "            if hist_SM_5[i]==0:\n",
    "                hist_SM_5[i] = min_back\n",
    "\n",
    "        # now divide by the number of possible ensembles\n",
    "        back_prom_5 = hist_SM_5/N_ensembles_back\n",
    "\n",
    "        # same for signal\n",
    "        hist_NP_5, _ = np.histogramdd([data_grid_NP_5], bins = [bin_edges])\n",
    "\n",
    "        sig_prom_5 = hist_NP_5/N_ensembles_sig\n",
    "\n",
    "        # then the signif Z^binned-Asimov:\n",
    "        Z_bins_XG_aux = ( 2* sum( ( back_prom_5 * np.log( back_prom_5 / (sig_prom_5+back_prom_5) ) ) + sig_prom_5 ) )**0.5\n",
    "\n",
    "        \n",
    "        \n",
    "#         chi2_zeros.append(aux_chi2)\n",
    "#         chi2_N_zeros.append(aux_chi2_N)\n",
    "#         MSE_zeros.append(aux_chi2_sin)\n",
    "        poiss_zeros.append(aux_poiss)\n",
    "        Z_bins_XG_CV_rd_zeros.append(Z_bins_XG_aux)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebcc199",
   "metadata": {},
   "source": [
    "#### SELECT THE BINNING with MINIMUM METRIC VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50340c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "\n",
    "# metric value\n",
    "# poiss_per_bin # asking for a min number of events per bin\n",
    "# poiss_per_bin_zeros # replacing the zeros\n",
    "\n",
    "# metric value (but bins equal size)\n",
    "# poiss_per_bin_eqsize # asking for a min number of events per bin\n",
    "# poiss_per_bin_eqsize_zeros # replacing the zeros\n",
    "\n",
    "# Z value\n",
    "# Z_poiss_per_bin # asking for a min number of events per bin\n",
    "# Z_poiss_per_bin_zeros # replacing the zeros\n",
    "\n",
    "# Z value (but bins equal size) is done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7410af",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# METRIC VALUE #\n",
    "################\n",
    "\n",
    "# chi2_per_bin = []\n",
    "# chi2_N_per_bin = []\n",
    "# MSE_per_bin = []\n",
    "poiss_per_bin = []\n",
    "\n",
    "# chi2_per_bin_eqsize = []\n",
    "# chi2_N_per_bin_eqsize = []\n",
    "# MSE_per_bin_eqsize = []\n",
    "poiss_per_bin_eqsize = []\n",
    "\n",
    "for i in range(len(B_bins_mean)):\n",
    "#     chi2_per_bin.append( np.min(chi2[ntrials*i:ntrials*(i+1)]) )\n",
    "#     chi2_N_per_bin.append( np.min(chi2_N[ntrials*i:ntrials*(i+1)]) )\n",
    "#     MSE_per_bin.append( np.min(MSE[ntrials*i:ntrials*(i+1)]) )\n",
    "    poiss_per_bin.append( np.min(poiss[ntrials*i:ntrials*(i+1)]) )\n",
    "    \n",
    "#     chi2_per_bin_eqsize.append( chi2[ntrials*i] )\n",
    "#     chi2_N_per_bin_eqsize.append( chi2_N[ntrials*i] )\n",
    "#     MSE_per_bin_eqsize.append( MSE[ntrials*i] )\n",
    "    poiss_per_bin_eqsize.append( poiss[ntrials*i] )\n",
    "    \n",
    "    \n",
    "    \n",
    "###########\n",
    "# Z VALUE #\n",
    "###########\n",
    "\n",
    "# Z_chi2_per_bin = []\n",
    "# Z_chi2_N_per_bin = []\n",
    "# Z_MSE_per_bin = []\n",
    "Z_poiss_per_bin = []\n",
    "\n",
    "for i in range(len(B_bins_mean)):\n",
    "#     Z_chi2_per_bin.append( Z_bins_XG_CV_rd[np.argmin(chi2[ntrials*i:ntrials*(i+1)]) + ntrials*i] )\n",
    "#     Z_chi2_N_per_bin.append( Z_bins_XG_CV_rd[np.argmin(chi2_N[ntrials*i:ntrials*(i+1)]) + ntrials*i] )\n",
    "#     Z_MSE_per_bin.append( Z_bins_XG_CV_rd[np.argmin(MSE[ntrials*i:ntrials*(i+1)]) + ntrials*i] )\n",
    "    Z_poiss_per_bin.append( Z_bins_XG_CV_rd[np.argmin(poiss[ntrials*i:ntrials*(i+1)]) + ntrials*i] )  \n",
    "    \n",
    "    \n",
    "    \n",
    "# SAME REPLACING THE ZEROS\n",
    "\n",
    "################\n",
    "# METRIC VALUE #\n",
    "################\n",
    "\n",
    "# chi2_per_bin_zeros = []\n",
    "# chi2_N_per_bin_zeros = []\n",
    "# MSE_per_bin_zeros = []\n",
    "poiss_per_bin_zeros = []\n",
    "\n",
    "# chi2_per_bin_eqsize_zeros = []\n",
    "# chi2_N_per_bin_eqsize_zeros = []\n",
    "# MSE_per_bin_eqsize_zeros = []\n",
    "poiss_per_bin_eqsize_zeros = []\n",
    "\n",
    "for i in range(len(B_bins_mean)):\n",
    "#     chi2_per_bin_zeros.append( np.min(chi2_zeros[ntrials*i:ntrials*(i+1)]) )\n",
    "#     chi2_N_per_bin_zeros.append( np.min(chi2_N_zeros[ntrials*i:ntrials*(i+1)]) )\n",
    "#     MSE_per_bin_zeros.append( np.min(MSE_zeros[ntrials*i:ntrials*(i+1)]) )\n",
    "    poiss_per_bin_zeros.append( np.min(poiss_zeros[ntrials*i:ntrials*(i+1)]) )\n",
    "    \n",
    "#     chi2_per_bin_eqsize_zeros.append( chi2_zeros[ntrials*i] )\n",
    "#     chi2_N_per_bin_eqsize_zeros.append( chi2_N_zeros[ntrials*i] )\n",
    "#     MSE_per_bin_eqsize_zeros.append( MSE_zeros[ntrials*i] )\n",
    "    poiss_per_bin_eqsize_zeros.append( poiss_zeros[ntrials*i] )\n",
    "    \n",
    "    \n",
    "###########\n",
    "# Z VALUE #\n",
    "###########\n",
    "\n",
    "# Z_chi2_per_bin_zeros = []\n",
    "# Z_chi2_N_per_bin_zeros = []\n",
    "# Z_MSE_per_bin_zeros = []\n",
    "Z_poiss_per_bin_zeros = []\n",
    "\n",
    "for i in range(len(B_bins_mean)):\n",
    "#     Z_chi2_per_bin_zeros.append( Z_bins_XG_CV_rd_zeros[np.argmin(chi2_zeros[ntrials*i:ntrials*(i+1)]) + ntrials*i] )\n",
    "#     Z_chi2_N_per_bin_zeros.append( Z_bins_XG_CV_rd_zeros[np.argmin(chi2_N_zeros[ntrials*i:ntrials*(i+1)]) + ntrials*i] )\n",
    "#     Z_MSE_per_bin_zeros.append( Z_bins_XG_CV_rd_zeros[np.argmin(MSE_zeros[ntrials*i:ntrials*(i+1)]) + ntrials*i] )\n",
    "    Z_poiss_per_bin_zeros.append( Z_bins_XG_CV_rd_zeros[np.argmin(poiss_zeros[ntrials*i:ntrials*(i+1)]) + ntrials*i] )   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edd3ca",
   "metadata": {},
   "source": [
    "####  SELECT THE BINNING with MAXIMUM Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9aa01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "\n",
    "# Z value\n",
    "# maxZ_per_bin # asking for a min number of events per bin\n",
    "# maxZ_per_bin_zeros # replacing the zeros\n",
    "\n",
    "# Z value (but bins equal size) (SHOULD BE THE SAME AS IN THE EQ SIZE SECTION)\n",
    "# maxZ_per_bin_eqsize # asking for a min number of events per bin\n",
    "# maxZ_per_bin_eqsize_zeros # replacing the zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27dece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Z VALUE #\n",
    "###########\n",
    "\n",
    "maxZ_per_bin = []\n",
    "maxZ_per_bin_eqsize = []\n",
    "\n",
    "for i in range(len(B_bins_mean)):\n",
    "    maxZ_per_bin.append( np.max(Z_bins_XG_CV_rd[ntrials*i:ntrials*(i+1)]) )\n",
    "    maxZ_per_bin_eqsize.append( Z_bins_XG_CV_rd[ntrials*i] )\n",
    "    \n",
    "\n",
    "# SAME REPLACING THE ZEROS\n",
    "\n",
    "\n",
    "maxZ_per_bin_zeros = []\n",
    "maxZ_per_bin_eqsize_zeros = []\n",
    "\n",
    "for i in range(len(B_bins_mean)):\n",
    "    maxZ_per_bin_zeros.append( np.max(Z_bins_XG_CV_rd_zeros[ntrials*i:ntrials*(i+1)]) )\n",
    "    maxZ_per_bin_eqsize_zeros.append( Z_bins_XG_CV_rd_zeros[ntrials*i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19c694",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dab27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# EQUAL SIZE BINS #\n",
    "###################\n",
    "\n",
    "# Z_bins_XG_CV # asking for a min number of events per bin (NO STAT ERROR)\n",
    "# Z_bins_XG_CV_zeros # replacing the zeros (NO STAT ERROR)\n",
    "\n",
    "\n",
    "# Z_bins_XG_CV_stat # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_stat_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_stat_min # central value -1sigma\n",
    "\n",
    "# Z_bins_XG_CV_stat_zeros # replacing the zeros\n",
    "# Z_bins_XG_CV_stat_zeros_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_stat_zeros_min # central value -1sigma\n",
    "\n",
    "\n",
    "#############################################\n",
    "# EQUAL NUMBER OF BACKGROUND EVENTS per BIN #\n",
    "#############################################\n",
    "\n",
    "# Z_bins_XG_CV_eqBperbin # asking for a min number of events per bin (NO STAT ERROR)\n",
    "# no replacing zeros because all bins have the same number of events\n",
    "\n",
    "\n",
    "# Z_bins_XG_CV_eqBperbin_stat # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_eqBperbin_stat_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_eqBperbin_stat_min # central value -1sigma\n",
    "\n",
    "\n",
    "#######################\n",
    "# MINIMIZING A METRIC #\n",
    "#######################\n",
    "\n",
    "# Z_poiss_per_bin # asking for a min number of events per bin\n",
    "# Z_poiss_per_bin_zeros # replacing the zeros\n",
    "\n",
    "\n",
    "################\n",
    "# MAXIMIZING Z #\n",
    "################\n",
    "\n",
    "# maxZ_per_bin # asking for a min number of events per bin\n",
    "# maxZ_per_bin_zeros # replacing the zeros\n",
    "\n",
    "# equal size (SHOULD BE THE SAME AS IN THE EQ SIZE SECTION)\n",
    "# maxZ_per_bin_eqsize # asking for a min number of events per bin\n",
    "# maxZ_per_bin_eqsize_zeros # replacing the zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548502aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "print(' check that the grid works, this should be identity ')\n",
    "\n",
    "plt.plot(maxZ_per_bin_eqsize, Z_bins_XG_CV, '.', color = 'red', label='Equal size bins')\n",
    "plt.plot(maxZ_per_bin_eqsize_zeros, Z_bins_XG_CV_zeros, '.', color = 'magenta', label='Equal size bins (zeros)')\n",
    "\n",
    "#plt.title('')\n",
    "plt.xlabel('Z', fontsize = 12)\n",
    "plt.ylabel('Z', fontsize = 12)\n",
    "#plt.ylim([5.6,6.8])\n",
    "plt.legend(fontsize = 12)\n",
    "#plt.savefig(rootir+'random-10k.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# PLOTS #\n",
    "#########\n",
    "\n",
    "print('fd', B_bins_mean[0])\n",
    "print('doane', B_bins_mean[1])\n",
    "print('sturges', B_bins_mean[2])\n",
    "\n",
    "\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV, '.', color = 'red', label='Equal size bins')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat, 'x', color = 'red', label='Equal size bins stat')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_plus, 'x', color = 'red')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_min, 'x', color = 'red')\n",
    "\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_zeros, '.', color = 'magenta', label='Equal size bins (zeros)')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_zeros, 'x', color = 'magenta', label='Equal size bins stat (zeros)')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_zeros_plus, 'x', color = 'magenta')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_zeros_min, 'x', color = 'magenta')\n",
    "\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin, '.', color = 'blue', label='Equal background events per bin')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin_stat, 'x', color = 'blue', label='Equal background events per bin stat')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin_stat_plus, 'x', color = 'blue')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin_stat_min, 'x', color = 'blue')\n",
    "\n",
    "plt.plot(B_bins_mean, Z_poiss_per_bin, '.', color = 'green', label='Random bins (min metric)')\n",
    "plt.plot(B_bins_mean, Z_poiss_per_bin_zeros, '.', color = 'purple', label='Random bins (min metric) (zeros)')\n",
    "plt.plot(B_bins_mean, maxZ_per_bin, '.', color = 'darkorange', label='Random bins (max Z)')\n",
    "plt.plot(B_bins_mean, maxZ_per_bin_zeros, '.', color = 'gray', label='Random bins (max Z) (zeros)')\n",
    "\n",
    "#plt.title('')\n",
    "plt.xlabel('$N_{bin}$', fontsize = 12)\n",
    "plt.ylabel('Z', fontsize = 12)\n",
    "#plt.ylim([5.6,6.8])\n",
    "plt.legend(fontsize = 12)\n",
    "#plt.savefig(rootir+'random-10k.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527baf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61bb1605",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLL+KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6a6cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE KDE TO ESTIMATE THE CLASSIFIER OUTPUT PDFs\n",
    "\n",
    "\n",
    "\n",
    "# FIND THE BANDWIDTH  # CHECK IF GOOD RESULTS WITH THIS PARAMETERS\n",
    "bandwidth = np.logspace(-4.0, 0.05, 50)\n",
    "num_evs_toKDE = 20000\n",
    "\n",
    "\n",
    "kde = KernelDensity(kernel='epanechnikov')\n",
    "grid = GridSearchCV(kde, {'bandwidth': bandwidth})\n",
    "grid.fit(np.c_[pred_XG_SM[:num_evs_toKDE]])\n",
    "print('Background: ', grid.best_estimator_)\n",
    "\n",
    "SM_bandwidth = grid.best_estimator_.bandwidth\n",
    "\n",
    "\n",
    "\n",
    "kde = KernelDensity(kernel='epanechnikov')\n",
    "grid = GridSearchCV(kde, {'bandwidth': bandwidth})\n",
    "grid.fit(np.c_[pred_XG_NP[:num_evs_toKDE]])\n",
    "print('Signal: ', grid.best_estimator_)\n",
    "\n",
    "NP_bandwidth = grid.best_estimator_.bandwidth\n",
    "\n",
    "\n",
    "\n",
    "# with each calculated bandwidth estimate the pdf with KDE to the classifier output (for background and signal)\n",
    "# notice: epanechnikov kernel\n",
    "kde_bkg = KernelDensity(kernel=\"epanechnikov\", bandwidth=SM_bandwidth).fit(np.c_[pred_XG_SM, np.zeros(len(pred_XG_SM)) ])\n",
    "kde_sig = KernelDensity(kernel=\"epanechnikov\", bandwidth=NP_bandwidth).fit(np.c_[pred_XG_NP, np.ones(len(pred_XG_NP)) ])\n",
    "\n",
    "\n",
    "\n",
    "# TO NORMALIZE TO 1, COMPUTE THE AREA\n",
    "\n",
    "# range\n",
    "min_val = np.min([np.min(pred_XG_SM),np.min(pred_XG_NP)])\n",
    "max_val = np.max([np.max(pred_XG_SM),np.max(pred_XG_NP)])\n",
    "\n",
    "s_vals = np.linspace(min_val,max_val,1000)\n",
    "\n",
    "\n",
    "# evaluate the densities for each value of s (~bins)\n",
    "dens_bkg = np.exp(kde_bkg.score_samples(np.c_[s_vals, np.zeros(len(s_vals)) ]) )\n",
    "dens_sig = np.exp(kde_sig.score_samples(np.c_[s_vals, np.ones(len(s_vals)) ]) )\n",
    "\n",
    "\n",
    "# Area\n",
    "factor_aux_SM = sum(dens_bkg*(s_vals[1]-s_vals[0]))\n",
    "factor_aux_NP = sum(dens_sig*(s_vals[1]-s_vals[0]))\n",
    "\n",
    "# normalize\n",
    "dens_bkg = dens_bkg / factor_aux_SM\n",
    "dens_sig = dens_sig / factor_aux_NP\n",
    "\n",
    "\n",
    "\n",
    "# plot to check the estimation \n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.hist(pred_XG_SM, 25, range=[0,1], density=True, color='blue',alpha=0.5, linewidth=2, label=r'Binned $\\tilde{p}_{b}(o(x))$');\n",
    "plt.hist(pred_XG_NP, 25, range=[0,1], density=True, color='red',alpha=0.5, linewidth=2, label=r'Binned $\\tilde{p}_{s}(o(x))$');\n",
    "\n",
    "plt.plot(s_vals,dens_bkg,color='blue',label=r'KDE $\\tilde{p}_{b}(o(x))$',linestyle='dashed');\n",
    "plt.plot(s_vals,dens_sig,color='red',label=r'KDE $\\tilde{p}_{s}(o(x))$',linestyle='dashed');\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Classication score (XGBoost)\",fontsize=14)\n",
    "plt.ylabel(\"Fraction of events/bin size\",fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper center',fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fe9aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MLL+KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVED IN:\n",
    "\n",
    "# store_Z_MLL_KDE   # Z for MLL+KDE\n",
    "# store_Z_MLL_KDE_plus # central value +1sigma statistic\n",
    "# store_Z_MLL_KDE_min # central value -1sigma statistic\n",
    "\n",
    "# same but fixing mu=0\n",
    "# store_Z_MLL_KDE_mu0\n",
    "# store_Z_MLL_KDE_mu0_plus\n",
    "# store_Z_MLL_KDE_mu0_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9123844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR EXCLUSION:\n",
    "# we need to evaluate the KDE densities with the classifier output of BACKGROUND EVENTS\n",
    "\n",
    "# FOR DISCOVERY:\n",
    "# we need to evaluate the KDE densities with the classifier output of BACKGROUND and SIGNAL EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# EVALUATE EVERY POINT IN THE KDE (its faster to de it all at once) #\n",
    "#####################################################################\n",
    "\n",
    "# evaluate every BACKGROUND point in the BACKGROUND PDF (obtained with KDE)\n",
    "KDE_SM_pred_SM = np.exp(kde_bkg.score_samples(np.c_[pred_XG_SM, np.zeros(len(pred_XG_SM)) ]) )\n",
    "\n",
    "# evaluate every BACKGROUND point in the SIGNAL (yes signal) PDF (obtained with KDE)\n",
    "KDE_NP_pred_SM = np.exp(kde_sig.score_samples(np.c_[pred_XG_SM, np.ones(len(pred_XG_SM)) ]) )\n",
    "\n",
    "\n",
    "# Normalize\n",
    "\n",
    "KDE_SM_pred_SM = KDE_SM_pred_SM / factor_aux_SM\n",
    "KDE_NP_pred_SM = KDE_NP_pred_SM / factor_aux_NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_muhat_mean_MLL_KDE = []\n",
    "\n",
    "store_Z_MLL_KDE = []\n",
    "store_Z_MLL_KDE_mu0 = []\n",
    "\n",
    "store_Z_MLL_KDE_std = []\n",
    "store_Z_MLL_KDE_std_mu0 = []\n",
    "\n",
    "\n",
    "indices = [i for i in range(len(KDE_NP_pred_SM))]\n",
    "\n",
    "\n",
    "# this loops computes everything for different cases\n",
    "# for example, for different multiple of S_expected = [100,200,300]\n",
    "# replace    for iii in range(0,1):     --->    for iii in range(len(S_expected)):\n",
    "# and replace everywhere    S_expected  --->    S_expected[iii]\n",
    "for iii in range(0,1):\n",
    "    \n",
    "    print('B_expected: ', B_expected)\n",
    "    print('S_expected: ', S_expected)\n",
    "    print('n_ensembles (initial): ', n_ensembles)\n",
    "\n",
    "\n",
    "    # to construct ensembles B and S events are taken from Poisson distributions\n",
    "    mu = S_expected + B_expected\n",
    "\n",
    "\n",
    "    # Letś find the number of events per ensemble such that we get at least one ensemble populated if events are taken from a Poisson distribution\n",
    "\n",
    "    # around the mean its populated so let's try (proposed range to be checked)\n",
    "    list_events_per_ensembles = [i for i in range(int(mu*0.9),int(mu*1.1))]\n",
    "    to_check = len(list_events_per_ensembles)\n",
    "\n",
    "    # I want at least one ensemble populated\n",
    "    list_nums_ensembles = [ int( poisson.pmf(list_events_per_ensembles[i],mu)*n_ensembles ) for i in range(len(list_events_per_ensembles)) ]\n",
    "\n",
    "\n",
    "\n",
    "    # Remove from the list the elements without at least 1 ensemble possible\n",
    "    for i in range(len(list_events_per_ensembles)):\n",
    "        if list_nums_ensembles[i] > 1:\n",
    "            list_events_per_ensembles = list_events_per_ensembles[i:]\n",
    "            list_nums_ensembles = list_nums_ensembles[i:]\n",
    "            break\n",
    "\n",
    "\n",
    "    for i in range(len(list_events_per_ensembles)):\n",
    "        if list_nums_ensembles[i] < 1:\n",
    "            list_events_per_ensembles = list_events_per_ensembles[:i]\n",
    "            list_nums_ensembles = list_nums_ensembles[:i]\n",
    "            break\n",
    "\n",
    "    print('\\n If ', to_check, ' = ', len(list_events_per_ensembles), '   then the proposed range has to be extended')\n",
    "\n",
    "    print('n_ensembles (actual): ', sum(list_nums_ensembles))\n",
    "\n",
    "\n",
    "\n",
    "    # lists of S and B events per ensemble, w.r.t the total of number of events per ensemble found above:\n",
    "\n",
    "    p_berno = S_expected/(S_expected+B_expected)\n",
    "\n",
    "    list_S_per_ensembles = []\n",
    "    list_B_per_ensembles = []\n",
    "\n",
    "    for jj in range(len(list_events_per_ensembles)):\n",
    "        list_S_per_ensembles.append( int(p_berno * list_events_per_ensembles[jj]) )\n",
    "        list_B_per_ensembles.append( list_events_per_ensembles[jj] - int(p_berno * list_events_per_ensembles[jj]) )\n",
    "\n",
    "    ######\n",
    "    # NOW I HAVE 4 LISTS:\n",
    "    # list_events_per_ensembles     list with the number of events per ensemble (its a range)\n",
    "    # list_nums_ensembles           list with the number of ensembles, w.r.t the 1st list\n",
    "    # list_S_per_ensembles          list with the number of signal events in each ensembles, w.r.t the 1st list\n",
    "    # list_B_per_ensembles          list with the number of background events in each ensembles, w.r.t the 1st list\n",
    "    ######\n",
    "\n",
    "\n",
    "\n",
    "    print('\\n This may take long... \\n')\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # NOW LETS APPLY THE METHOD #\n",
    "    #############################\n",
    "\n",
    "    muhat_selected_KDE_list = []\n",
    "    q_muhat_KDE = []\n",
    "    q_muhat_KDE_mu0 = []\n",
    "    \n",
    "    for bb in range(len(list_nums_ensembles)):\n",
    "\n",
    "        for kk in range(list_nums_ensembles[bb]):\n",
    "            \n",
    "            # KDE\n",
    "            ran_ind = np.random.choice(indices, list_B_per_ensembles[bb])\n",
    "\n",
    "            KDE_SM_pred_SM_shuf = []\n",
    "            KDE_NP_pred_SM_shuf = []\n",
    "\n",
    "            for i in ran_ind:\n",
    "                KDE_SM_pred_SM_shuf.append(KDE_SM_pred_SM[i])\n",
    "                KDE_NP_pred_SM_shuf.append(KDE_NP_pred_SM[i])\n",
    "\n",
    "            KDE_SM_pred_SM_shuf  = np.array(KDE_SM_pred_SM_shuf)\n",
    "            KDE_NP_pred_SM_shuf  = np.array(KDE_NP_pred_SM_shuf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # p_b(o(x_ensemble)) =    concatenate: p_b(o(B_ensemble)) and p_b(o(S_ensemble))  NOTICE THE o(x)\n",
    "            prob_x_given_B = np.ndarray.tolist( KDE_SM_pred_SM_shuf ) #+ np.ndarray.tolist( KDE_SM_pred_NP_shuf )\n",
    "\n",
    "            # p_s(o(x_ensemble)) =    concatenate: p_s(o(B_ensemble)) and p_s(o(S_ensemble))  NOTICE THE o(x)\n",
    "            prob_x_given_S = np.ndarray.tolist( KDE_NP_pred_SM_shuf ) #+ np.ndarray.tolist( KDE_NP_pred_NP_shuf )\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # NOW WE HAVE p_{s,b}(x_ensemble) for this particular ensemble\n",
    "            # WE NEED TO ESTIMATE mu_hat for this particular ensemble\n",
    "            # we are going to obtain a mu_hat with a grid of values for this particular ensemble\n",
    "\n",
    "            B_prob_x_given_B = [x * B_expected for x in prob_x_given_B]\n",
    "            \n",
    "            sum_muhat_zero = sum ( [(x*1.) / ( (x * 0. * S_expected) + y ) for x, y in zip(prob_x_given_S, B_prob_x_given_B)] )\n",
    "            sum_muhat_one = sum ( [(x*1.) / ( (x * 1. * S_expected) + y ) for x, y in zip(prob_x_given_S, B_prob_x_given_B)] )\n",
    "\n",
    "            # grid, mu_hat is around 1\n",
    "            muhat_test = np.arange(0., 1., 0.05).tolist()\n",
    "\n",
    "            muhat_selected_KDE = 0.0\n",
    "\n",
    "            if sum_muhat_zero < sum_muhat_one and sum_muhat_zero < 1:\n",
    "\n",
    "                for vv in range(len(muhat_test)):\n",
    "\n",
    "                    mu_hat_condition_equal_1 = sum ( [(x*1.) / ( (x * muhat_test[vv] * S_expected) + y ) for x, y in zip(prob_x_given_S, B_prob_x_given_B)] )\n",
    "\n",
    "                    if mu_hat_condition_equal_1 > 1:\n",
    "                        muhat_selected_KDE = muhat_test[vv]\n",
    "                        break\n",
    "\n",
    "            elif sum_muhat_zero > sum_muhat_one and sum_muhat_zero > 1:\n",
    "\n",
    "                for vv in range(len(muhat_test)):\n",
    "\n",
    "                    mu_hat_condition_equal_1 = sum ( [(x*1.) / ( (x * muhat_test[vv] * S_expected) + y ) for x, y in zip(prob_x_given_S, B_prob_x_given_B)] )\n",
    "\n",
    "                    if mu_hat_condition_equal_1 < 1:\n",
    "                        muhat_selected_KDE = muhat_test[vv]\n",
    "                        break\n",
    "\n",
    "\n",
    "            muhat_selected_KDE_list.append(muhat_selected_KDE)\n",
    "\n",
    "\n",
    "\n",
    "            # NOW THAT WE HAVE mu_hat FOR THIS ENSEMBLE, CALCULATE THE TEST STATISTIC FOR THIS ENSEMBLE\n",
    "            # and append it (we need the median over lots of ensembles)\n",
    "            #q_muhat.append( 2 * ( (-1.*muhat_selected * S_expected) + sum( [np.log( 1 + ( (muhat_selected*S_expected/B_expected) * (x / y) ) ) for x, y in zip(prob_x_given_S, prob_x_given_B)] ) ) )\n",
    "            #q_muhat_mu0.append( 2 * ( (-1.*1. * S_expected) + sum( [np.log( 1 + ( (1.*S_expected/B_expected) * (x / y) ) ) for x, y in zip(prob_x_given_S, prob_x_given_B)] ) ) )\n",
    "            # EXCLUSION:\n",
    "            q_muhat_KDE.append( 2 * ( ( (1.-muhat_selected_KDE) * S_expected ) - sum( [np.log( ( (B_expected*y) + (S_expected*x) ) / ( (B_expected*y) + (muhat_selected_KDE*S_expected*x) ) ) for x, y in zip(prob_x_given_S, prob_x_given_B)] ) ) )\n",
    "            q_muhat_KDE_mu0.append( 2 * ( ( (1.-0.) * S_expected ) - sum( [np.log( ( (B_expected*y) + (S_expected*x) ) / ( (B_expected*y) + (0.*S_expected*x) ) ) for x, y in zip(prob_x_given_S, prob_x_given_B)] ) ) )\n",
    "\n",
    "\n",
    "    # Histogram of q_muhats\n",
    "\n",
    "    weights = np.ones_like(q_muhat_KDE)/float(len(q_muhat_KDE))\n",
    "    nMIX, binsMIX, patchesMIX = plt.hist(q_muhat_KDE, 25, weights=weights, histtype='step', color='blue', linewidth=2)\n",
    "    #plt.xlim(0,1)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"$q_0(\\hat{\\mu})$\",fontsize=16)\n",
    "    plt.ylabel(\"Fraction of ensembles\",fontsize=16)\n",
    "    plt.title(r\"$\\bar{B}$=%0.2i, $\\bar{S}=$%0.2i\" % (B_expected,S_expected),fontsize=14)\n",
    "    plt.grid()\n",
    "    #plt.legend(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Finally calculate muhat_mean and Z_gaussian\n",
    "    \n",
    "    # Remove nan if any\n",
    "    q_muhat_KDE_mu0 = [x for x in q_muhat_KDE_mu0 if x == x]\n",
    "    for jk in range(len(q_muhat_KDE_mu0)):\n",
    "        if q_muhat_KDE_mu0[jk] < 0:\n",
    "            q_muhat_KDE_mu0[jk] = 0\n",
    "\n",
    "    q_muhat_KDE_median_mu0 = np.median(q_muhat_KDE_mu0)\n",
    "    Z_KDE_mu0 = abs(q_muhat_KDE_median_mu0)**0.5\n",
    "    store_Z_MLL_KDE_mu0.append(Z_KDE_mu0)\n",
    "    \n",
    "    q_muhat_KDE_std_mu0 = np.std(q_muhat_KDE_mu0)\n",
    "    Z_KDE_std_mu0 = q_muhat_KDE_std_mu0/(2.*Z_KDE_mu0)\n",
    "    store_Z_MLL_KDE_std_mu0.append(Z_KDE_std_mu0)\n",
    "    \n",
    "\n",
    "    # Finally calculate muhat_mean and Z_gaussian\n",
    "    muhat_mean_MLL_KDE = np.mean(muhat_selected_KDE_list)\n",
    "    store_muhat_mean_MLL_KDE.append(muhat_mean_MLL_KDE)\n",
    "\n",
    "    # Remove nan if any\n",
    "    q_muhat_KDE = [x for x in q_muhat_KDE if x == x]\n",
    "    for jk in range(len(q_muhat_KDE)):\n",
    "        if q_muhat_KDE[jk] < 0:\n",
    "            q_muhat_KDE[jk] = 0\n",
    "\n",
    "    q_muhat_KDE_median = np.median(q_muhat_KDE)\n",
    "    Z_KDE = abs(q_muhat_KDE_median)**0.5\n",
    "    store_Z_MLL_KDE.append(Z_KDE)\n",
    "    \n",
    "    q_muhat_KDE_std = np.std(q_muhat_KDE)\n",
    "    Z_KDE_std = q_muhat_KDE_std/(2.*Z_KDE)\n",
    "    store_Z_MLL_KDE_std.append(Z_KDE_std)\n",
    "\n",
    "    print('muhat mean: ', muhat_mean_MLL_KDE)\n",
    "    print('median q_muhat_KDE: ', q_muhat_KDE_median)\n",
    "    print('Z_KDE: ', Z_KDE)\n",
    "    print('Z_KDE mu=0: ', Z_KDE_mu0)\n",
    "    print('std Z_KDE: ', Z_KDE_std)\n",
    "    print('std Z_KDE mu=0: ', Z_KDE_std_mu0)\n",
    "\n",
    "    print('\\n -------------------------------- \\n')\n",
    "    \n",
    "    \n",
    "store_Z_MLL_KDE_plus = [i+j for i, j in zip(store_Z_MLL_KDE, store_Z_MLL_KDE_std)]\n",
    "store_Z_MLL_KDE_min = [i-j for i, j in zip(store_Z_MLL_KDE, store_Z_MLL_KDE_std)]\n",
    "\n",
    "store_Z_MLL_KDE_mu0_plus = [i+j for i, j in zip(store_Z_MLL_KDE_mu0, store_Z_MLL_KDE_std_mu0)]\n",
    "store_Z_MLL_KDE_mu0_min = [i-j for i, j in zip(store_Z_MLL_KDE_mu0, store_Z_MLL_KDE_std_mu0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3a01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7ae981",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- #\n",
    "# BIN LIKELIHOOD #\n",
    "# -------------- #\n",
    "\n",
    "###################\n",
    "# EQUAL SIZE BINS #\n",
    "###################\n",
    "\n",
    "# Z_bins_XG_CV # asking for a min number of events per bin (NO STAT ERROR)\n",
    "# Z_bins_XG_CV_zeros # replacing the zeros (NO STAT ERROR)\n",
    "\n",
    "\n",
    "# Z_bins_XG_CV_stat # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_stat_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_stat_min # central value -1sigma\n",
    "\n",
    "# Z_bins_XG_CV_stat_zeros # replacing the zeros\n",
    "# Z_bins_XG_CV_stat_zeros_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_stat_zeros_min # central value -1sigma\n",
    "\n",
    "\n",
    "#############################################\n",
    "# EQUAL NUMBER OF BACKGROUND EVENTS per BIN #\n",
    "#############################################\n",
    "\n",
    "# Z_bins_XG_CV_eqBperbin # asking for a min number of events per bin (NO STAT ERROR)\n",
    "# no replacing zeros because all bins have the same number of events\n",
    "\n",
    "\n",
    "# Z_bins_XG_CV_eqBperbin_stat # asking for a min number of events per bin\n",
    "# Z_bins_XG_CV_eqBperbin_stat_plus # central value +1sigma\n",
    "# Z_bins_XG_CV_eqBperbin_stat_min # central value -1sigma\n",
    "\n",
    "\n",
    "#######################\n",
    "# MINIMIZING A METRIC #\n",
    "#######################\n",
    "\n",
    "# Z_poiss_per_bin # asking for a min number of events per bin\n",
    "# Z_poiss_per_bin_zeros # replacing the zeros\n",
    "\n",
    "\n",
    "################\n",
    "# MAXIMIZING Z #\n",
    "################\n",
    "\n",
    "# maxZ_per_bin # asking for a min number of events per bin\n",
    "# maxZ_per_bin_zeros # replacing the zeros\n",
    "\n",
    "# equal size (SHOULD BE THE SAME AS IN THE EQ SIZE SECTION)\n",
    "# maxZ_per_bin_eqsize # asking for a min number of events per bin\n",
    "# maxZ_per_bin_eqsize_zeros # replacing the zeros\n",
    "\n",
    "\n",
    "\n",
    "# ------- #\n",
    "# MLL+KDE #\n",
    "# ------- #\n",
    "\n",
    "# store_Z_MLL_KDE   # Z for MLL+KDE\n",
    "# store_Z_MLL_KDE_plus # central value +1sigma statistic\n",
    "# store_Z_MLL_KDE_min # central value -1sigma statistic\n",
    "\n",
    "# same but fixing mu=0\n",
    "# store_Z_MLL_KDE_mu0\n",
    "# store_Z_MLL_KDE_mu0_plus\n",
    "# store_Z_MLL_KDE_mu0_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f070805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# PLOTS #\n",
    "#########\n",
    "\n",
    "print('fd', B_bins_mean[0])\n",
    "print('doane', B_bins_mean[1])\n",
    "print('sturges', B_bins_mean[2])\n",
    "\n",
    "\n",
    "# PLOT KDE IN BIN=0 (ACTUALLY UNBIN METHOD)\n",
    "no_bin_MLLKDE = [0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV, '.', color = 'red', label='Equal size bins')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat, 'x', color = 'red', label='Equal size bins stat')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_plus, 'x', color = 'red')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_min, 'x', color = 'red')\n",
    "\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_zeros, '.', color = 'magenta', label='Equal size bins (zeros)')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_zeros, 'x', color = 'magenta', label='Equal size bins stat (zeros)')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_zeros_plus, 'x', color = 'magenta')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_stat_zeros_min, 'x', color = 'magenta')\n",
    "\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin, '.', color = 'blue', label='Equal background events per bin')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin_stat, 'x', color = 'blue', label='Equal background events per bin stat')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin_stat_plus, 'x', color = 'blue')\n",
    "plt.plot(B_bins_mean, Z_bins_XG_CV_eqBperbin_stat_min, 'x', color = 'blue')\n",
    "\n",
    "plt.plot(B_bins_mean, Z_poiss_per_bin, '.', color = 'green', label='Random bins (min metric)')\n",
    "plt.plot(B_bins_mean, Z_poiss_per_bin_zeros, '.', color = 'purple', label='Random bins (min metric) (zeros)')\n",
    "plt.plot(B_bins_mean, maxZ_per_bin, '.', color = 'darkorange', label='Random bins (max Z)')\n",
    "plt.plot(B_bins_mean, maxZ_per_bin_zeros, '.', color = 'gray', label='Random bins (max Z) (zeros)')\n",
    "\n",
    "plt.plot(no_bin_MLLKDE, store_Z_MLL_KDE, 'x', color='pink', lw=lw, label='MLL+KDE stat')\n",
    "plt.plot(no_bin_MLLKDE, store_Z_MLL_KDE_plus, 'x', color='pink', lw=lw)\n",
    "plt.plot(no_bin_MLLKDE, store_Z_MLL_KDE_min, 'x', color='pink', lw=lw)\n",
    "\n",
    "#plt.title('')\n",
    "plt.xlabel('$N_{bin}$', fontsize = 12)\n",
    "plt.ylabel('Z', fontsize = 12)\n",
    "#plt.ylim([5.6,6.8])\n",
    "plt.legend(fontsize = 12)\n",
    "#plt.savefig(rootir+'random-10k.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
